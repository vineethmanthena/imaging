1)Upon reviewing the dataset, I noticed that it captures four distinct scenes of a parking lot at various times throughout the day over a specific period. Additionally, I observed that the cameras were positioned close to the ceiling, resulting in the roof occupying a significant portion of the image space and causing objects to appear out of focus. Furthermore, I noticed that the outer edges of the images exhibit curvature, indicative of barrel distortion. This distortion is likely a result of the wide field of view provided by the camera.


2)The code works like this: It takes in the directory that contains the images and makes a list out of it. Then the images were read using cv2.imread() before preprocessing. Before passing the images to compare_frames_change_detection fucntion the images were resized to the same size as there are of different sizes and the cv2.absdiff() only takes images of same type.
Before applying artithmetic operations on the images, in an attempt to reduce the effect of light, Histogram equalization is utilized to improve contrast and ensure consistent brightness levels across images, thereby facilitating more accurate comparison results.and i have also made some changes to the compare_frames_change_fucntion.
A threshold is applied to the computed similarity scores to distinguish between similar and dissimilar image pairs. Images with similarity scores below the threshold are classified as similar, while those exceeding the threshold are considered different.
To ensure thorough comparison, the code employs a secondary loop to compare each image with every other image in the dataset. This approach guards against overlooking subtle similarities between images, especially in cases where consecutive images may exhibit slight variations but still depict the same scene.
The threshold was set slightly higher in the second loop to account for highly illuminated images, which tend to produce larger differences when compared. While this approach may result in the loss of some information, it effectively filters out most of the unnecessary data, ensuring that only significant differences between images are considered. This adjustment helps prioritize the detection of meaningful variations while mitigating the impact of lighting conditions on the comparison process.
The decision to utilize two loops for comparison strikes a balance between comprehensive evaluation and computational efficiency. By initially comparing adjacent images and subsequently conducting a broader comparison across the entire dataset, the code delivers accurate and exhaustive analysis of image similarities.
